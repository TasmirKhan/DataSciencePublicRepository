{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e519d47",
   "metadata": {},
   "source": [
    "Training ML Algorithm on Iris Dataset\n",
    "This guide walks you through training a model on your own CSV dataset using scikit-learn.\n",
    "\n",
    "1. Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "2. Load Your CSV File\n",
    "data = pd.read_csv('data.csv')  # Replace with your actual CSV file path\n",
    "\n",
    "3. Separate Features and Label\n",
    "X = data.iloc[:, :-1]  # All columns except the last as features\n",
    "y = data.iloc[:, -1]   # Last column as label\n",
    "\n",
    "4. Train the Model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "The model is now trained on your complete dataset.\n",
    "\n",
    "5. Inference\n",
    "predictions = model.predict(X)  # Predict on the same/new data (for demonstration)\n",
    "print(predictions)  # Display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75447283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31596 33530  9262 62199 66287 67546 48150 30615 11327 62782 37768 36850\n",
      " 59411 50788 58409 24848 54830 60446 47542 23160 64583 41998 35230 17076\n",
      " 11805 39085 63571 22715 13750 56395 21232 61008 43903 14953 40093 33500\n",
      " 30418 61741 42314 56225 30449 25478 43179 59769 54881 33338 34899 12145\n",
      " 40101 10775 53961 39647 53619 53838 63780 27539 44738 65124 34616 22119\n",
      " 33159 62567 45099 18295 42710 69799 63178 32685 57343 33479 54172 41629\n",
      " 63863 50043 25033 44902 52571 23408 64739 65980 25420 24351 12131 59300\n",
      " 52825 19349 68931 52254 46225 46847 20453 26814 26263 20158 23735 23830\n",
      " 55893 52673 69470 31926 53066 42779 11373 18335 31741 18692 55295 53541\n",
      " 42057  9447 27583 30765 67287 31906 63211 27567 22139 54525 46230 60368\n",
      " 27520 27702 59934 33566 15657 45688 38134 18345 63476 63479 49185 57928\n",
      " 35413 13208 41455 57681 36018 62219 53991 16080 29902 59305 17486 46862\n",
      " 64126 66870 29158 48460 51856 43871 43208 28519 39379 36378 47892 62353\n",
      " 57996 22031 22536  8446 44683 56555 60261 25618 14587 39480 40994 28527\n",
      " 31569 19151 13558 67174 52739 40954 55448 55327 51837 43303 42700 35500\n",
      " 66192 10032  9252 13509 45842 21900 22523  9881 41037  9630 28789 68547\n",
      " 30523 25958 54151 56920 51852  9695 60410 22821 11262  9445 63415 65563\n",
      " 24436 17949 62722 31963 58818 37932 14901 59937 41487 16597 14855 26678\n",
      " 16263 55288 67397 33805 34143 19874 35529 28866 22079 57850 15243 37872\n",
      " 17018 63070 57500 62526 20100 65021 57459 27800 34910 37437 45588 19001\n",
      " 54675 27942 28862 19669 63683 61772 23916 18878 10985 40369 16112 49235\n",
      " 26931 35340  8336 50933 27363 53536 11968 41678 59148 56400 24279 11129\n",
      " 46215 46897 13850 28588 48214 19949 16519 34375 41082 19737  9134 18938\n",
      " 62028 32486 56356 34096 49115 13592 26108 60495 25270 35649 18997 41489\n",
      " 64830 17104 60509  8870 36684 47519 57649 42524 38957 41885 52369 43596\n",
      " 37866 38676 55764 58799 21878 47760 35559 54546 14771 24526 37896 39923\n",
      " 59913 44203 47390 20852 55574 51391 64221 61664  9848 39027 43464 42485\n",
      " 27456 17259 43554 54922 21409 11791 33864 44639 42574 25888 27692 31501\n",
      " 21304 62200 35527 65415 26074 23549 37963 33920 38826 44071 60265 24061\n",
      " 66226 36810 68006 65002 55966 30800 58656 51423 67897 49692 17940 11924\n",
      " 65767 36054 17783 45253 53397 21233 53669 32484 33068  8191 33074 12917\n",
      " 46599 33832 50928 28706 21682 34762 31383 66160 35796 31666 66817 33662\n",
      " 53159 42642 49830 45531 18234 65616 17221 19410 22519 69413  9051 52993\n",
      " 17765 19382 20580 64690 64563 40323 52757 68633 63472 19939 59257 37964\n",
      "  8307 64889 11359 37648 43944 42019 46134 35323 58669 14226 29689 38971\n",
      " 33954 63021 32423 38391 22330 12891 12992  9961 20497 60015 40551 18848\n",
      " 67838 63755 21255 12567 56847 47281 56003 28389 52523 66266 69576 69806\n",
      " 51919 24567 64907 11358 30999 50358 63949 18988 65880 48446 39521 13698\n",
      "  9273 35543 63805 39349 19241 58248 17497 49875 40703 52041 39954 16002\n",
      " 12247 49988 29698 67321 27738 18703 56240 57422 25570 69899 20392 52724\n",
      " 40299 23641 21998 14305 40726 26782 20721 47763 20427 54550 64451 28566\n",
      " 67055 10230 14511 57280 50229 60824 34177 12765 28354 31929 36820 54040\n",
      " 37523 13552  8627 19989 21780 14589 42812 36128 53939 59493 46652 35790\n",
      " 48953  8249 27309 62195 58126 33901 31576 39508 17175 33464 68281 24260\n",
      " 67461 43440 37546 48047 64683 66670 49430  9987 57242 33105 20948 61211\n",
      " 21026 10773 53927 17878 65535 50946 68967 64561 18377 61592 15347 41776\n",
      " 11783 63798 12298 12668 28671 42820 63161 68652 42484 41078 55159 28922\n",
      " 42028 53925 28316 19460 24968 38266 68143 38209 32000 65703 22011 10866\n",
      " 55133 13898 26395 47019 45707 12006 42393 18956 58042 38663 14078 37631\n",
      " 38140 64188 49691 11961 37277 59656 49574 60958 39417 30484 26103 37345\n",
      " 54326 47454  9587 64152 50571 58048 62710 65621 29031 34212 18350 26816\n",
      " 28288 37432 52222 56617 14837 42217 28884 13454 17424 44885 49637 51618\n",
      " 26412 55111 47613 28142 63056 45392 67381 67993 16848 57317 21136 61743\n",
      "  8589 28908 59973 69602 14509 48461 50222 57223 52476 53710 60732 65114\n",
      " 57420 17968 10462 17460 41783 68066 17275 36677 21269 65136  8406 15384\n",
      " 63201 30553 32366 52036 25369 19795 12485 49669 10618 38143 37425 30673\n",
      " 17603 47696 13368 12621 66829 68294 22719 37227 51894 15566 20306 61822\n",
      " 32042 23086 25387 35042 31888 43303 34514 26323 26019 17890 48863 63417\n",
      " 53487 18283 26279 54999 30908 69584 68742 55466 58225 45952 43170 45663\n",
      " 64483 52172 69381 55929 17343 18637 42724 47791 37134 54830 55101 11907\n",
      " 41575 65530 54799 12827 38607 21699 45292 55961 33883 56991 59436 13313\n",
      " 21598 53826 57909 36807 12887 11854 53226 67550 22536 11558 17772 58113\n",
      " 60999 63878 44343 66219 43186 44966 41769 62396 68728 47887 61218 27229\n",
      " 17673 35877 66001 39601 46084 24244 35356 24806 31099 52641 45034 48317\n",
      " 63468 27094 65796 18589 65221 67319  9657 40764 59693 47531 60227 11164\n",
      " 35542 26437 49247 46505 27601 36430 58599 14009 57759 12552 58916 17417\n",
      " 66579 49989 10671 14519 44730 20734 53890 60329 11722 12906 38096 48031\n",
      " 21699 29438 66819 51856 41576 49938 57028 67807 57877 40247 51461 35938\n",
      " 48469 25600 28435 26581 22191 27190 66122 58124 35386 39721 62786 21704\n",
      " 64635 10123 33174 52301 57376 55216 22586 39976 33416  9814 21001 58258\n",
      " 24508 27630 21380 56174 43699 54335 54806 20317 43739 42785 39980 31799\n",
      " 43183 37166 27480  9609  8717 27945 33592 36141 38009 53430 14782 34536\n",
      " 41816 33933 19618 16307 34671 48673 50761 18338 46346 54602 58772 14548\n",
      " 48149 29164 35526 39222 28176 10941 13695 47169 55947 55224 53865 33553\n",
      " 46965 68410 46218 33359 32816 63026 58705 69922 58164 16378  9881 47567\n",
      " 55365 21675 12586 33006 49198 30831 43113 24459 40443 50316 38595 13877\n",
      " 47553 56601 12922 65242 59482 12686 40766 22407 40006 39422 59054 20205\n",
      " 29054 31527 53947 26443 24524 58941 36202  8016 54142 69692 24848 28855\n",
      " 26211 68372 33095 46724 57241 45583 60003 10843 37301 34460 39918 36747\n",
      " 23972 66269 36310 30927 63053 58121  9094 46892 64499 60347 42172 68708\n",
      " 31324 28674 11982 53283 23790 20205 62707 32338 20748 29097 11092 61311\n",
      " 30692 67418 31862 32860 21971 22616 12933 12926 33763 11969 43733 12319\n",
      " 49743 47876 49909 28323 24428 42578 28950 51041 68842 49789 26293 14364\n",
      " 43349  8691 69363 38062]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv('1750577174509-smartphone_data.csv')\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08791310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "    sepallength  sepalwidth  petallength  petalwidth            class  \\\n",
      "0           5.4         3.0          4.5         1.5  Iris-versicolor   \n",
      "1           5.3         3.7          1.5         0.2      Iris-setosa   \n",
      "2           5.2         4.1          1.5         0.1      Iris-setosa   \n",
      "3           5.2         3.5          1.5         0.2      Iris-setosa   \n",
      "4           5.2         3.4          1.4         0.2      Iris-setosa   \n",
      "5           5.2         2.7          3.9         1.4  Iris-versicolor   \n",
      "6           5.1         3.8          1.9         0.4      Iris-setosa   \n",
      "7           5.1         3.8          1.6         0.2      Iris-setosa   \n",
      "8           5.1         3.8          1.5         0.3      Iris-setosa   \n",
      "9           5.1         3.7          1.5         0.4      Iris-setosa   \n",
      "10          5.1         3.5          1.4         0.2      Iris-setosa   \n",
      "11          5.1         3.5          1.4         0.3      Iris-setosa   \n",
      "12          5.1         3.4          1.5         0.2      Iris-setosa   \n",
      "13          5.1         3.3          1.7         0.5      Iris-setosa   \n",
      "14          5.1         2.5          3.0         1.1  Iris-versicolor   \n",
      "15          5.0         3.6          1.4         0.2      Iris-setosa   \n",
      "16          5.0         3.5          1.6         0.6      Iris-setosa   \n",
      "17          5.0         3.5          1.3         0.3      Iris-setosa   \n",
      "18          5.0         3.4          1.6         0.4      Iris-setosa   \n",
      "19          5.0         3.4          1.5         0.2      Iris-setosa   \n",
      "20          5.0         3.3          1.4         0.2      Iris-setosa   \n",
      "21          5.0         3.2          1.2         0.2      Iris-setosa   \n",
      "22          5.0         3.0          1.6         0.2      Iris-setosa   \n",
      "23          5.0         2.3          3.3         1.0  Iris-versicolor   \n",
      "24          5.0         2.0          3.5         1.0  Iris-versicolor   \n",
      "25          4.9         3.1          1.5         0.1      Iris-setosa   \n",
      "26          4.9         3.1          1.5         0.1      Iris-setosa   \n",
      "27          4.9         3.1          1.5         0.1      Iris-setosa   \n",
      "28          4.9         3.0          1.4         0.2      Iris-setosa   \n",
      "29          4.9         2.5          4.5         1.7   Iris-virginica   \n",
      "30          4.9         2.4          3.3         1.0  Iris-versicolor   \n",
      "31          4.8         3.4          1.9         0.2      Iris-setosa   \n",
      "32          4.8         3.4          1.6         0.2      Iris-setosa   \n",
      "33          4.8         3.1          1.6         0.2      Iris-setosa   \n",
      "\n",
      "          predicted  \n",
      "0   Iris-versicolor  \n",
      "1       Iris-setosa  \n",
      "2       Iris-setosa  \n",
      "3       Iris-setosa  \n",
      "4       Iris-setosa  \n",
      "5   Iris-versicolor  \n",
      "6       Iris-setosa  \n",
      "7       Iris-setosa  \n",
      "8       Iris-setosa  \n",
      "9       Iris-setosa  \n",
      "10      Iris-setosa  \n",
      "11      Iris-setosa  \n",
      "12      Iris-setosa  \n",
      "13      Iris-setosa  \n",
      "14  Iris-versicolor  \n",
      "15      Iris-setosa  \n",
      "16      Iris-setosa  \n",
      "17      Iris-setosa  \n",
      "18      Iris-setosa  \n",
      "19      Iris-setosa  \n",
      "20      Iris-setosa  \n",
      "21      Iris-setosa  \n",
      "22      Iris-setosa  \n",
      "23  Iris-versicolor  \n",
      "24  Iris-versicolor  \n",
      "25      Iris-setosa  \n",
      "26      Iris-setosa  \n",
      "27      Iris-setosa  \n",
      "28      Iris-setosa  \n",
      "29  Iris-versicolor  \n",
      "30  Iris-versicolor  \n",
      "31      Iris-setosa  \n",
      "32      Iris-setosa  \n",
      "33      Iris-setosa  \n",
      "Accuracy of the data is ->  0.9705882352941176\n",
      "Confusion Matrix:\n",
      "[[27  0  0]\n",
      " [ 0  6  0]\n",
      " [ 0  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        27\n",
      "Iris-versicolor       0.86      1.00      0.92         6\n",
      " Iris-virginica       0.00      0.00      0.00         1\n",
      "\n",
      "       accuracy                           0.97        34\n",
      "      macro avg       0.62      0.67      0.64        34\n",
      "   weighted avg       0.95      0.97      0.96        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install openpyxl\n",
    "from sklearn.metrics import accuracy_score\n",
    "data2 = pd.read_excel(\"1750577671457-iris-train.xlsx\")\n",
    "X_train = data2.iloc[:,:-1]\n",
    "y_train = data2.iloc[:,-1]\n",
    "\n",
    "data3 = pd.read_excel(\"1750577674984-iris-test.xlsx\")\n",
    "X_test = data3.iloc[:,:-1]\n",
    "y_test = data3.iloc[:,-1]\n",
    "result = data3.copy\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions2 = model.predict(X_test)\n",
    "data3[\"predicted\"] = predictions2\n",
    "print(data3)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions2)\n",
    "print(\"Accuracy of the data is -> \", accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions2))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
